<!DOCTYPE html>
<html lang="en" >
    <head>
        <meta charset="UTF-8">
        <title>ECSE424 Group 13 Notebook Observation and Proposal</title>
        <link rel='stylesheet' href='bootstrap.min.css'>
        <link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/material-design-iconic-font/2.2.0/css/material-design-iconic-font.min.css'>
        <link rel="stylesheet" href="style1.css">
        <style>
            h1 {text-align: center;}
            h2 {text-align: center;}
            h3,
            .h3 {
                text-align: center;
                font-size: 150%;
            }
            h4,
            .h4{
                text-align: center;
                font-size: 120%;
            }

	        .container{
		        text-align: left;
		        font-size: 18px;
		    }
            .image_map{
                width: 100%;
                height:auto;
            }
            .citation{
                font-size: 10px;
            }
            .cite{
                font-style: italic;
            }
        </style>
    </head>

    <body>

    <div id="viewport">
    <!-- Sidebar -->
    <div id="sidebar">
        <header>
        <a href="#">Deliverables</a>
        </header>
    <ul class="nav">
        <li>
            <a href="index.html">
            Home
            </a>
        </li>
        <li>
            <a href="Observation.html" class="active">
            Observations and Proposal
            </a>
        </li>
        <li>
            <a href="l-fi-prototype.html">
            Low-Fidelity Prototype and Test Plan
            </a>
        </li>
        <li>
            <a href="Computer-Prototype.html">
            Computer Prototype
            </a>
        </li>
        <li>
            <a href="Evaluation.html">
            Evaluation
            </a>
        </li>
        <li>
            <a href="Alpha_System.html">
            Alpha System
            </a>
        </li>
        <li>
            <a href="Beta_System.html">
            Beta System
            </a>
        </li>
    </ul>
  </div>
  <!-- Content -->
  <div id="content">
    <nav class="navbar navbar-default">
      <div class="container-fluid">
        
      </div>
    </nav>
    <h1>Welcome to ECSE424 HCI Group 13 Notebook</h1>
			<h2>Observations and Proposal</h2>
            <br>
            <hr>
            <br>
        <div class="container">
         <h3>I. Observing Users</h3>
         <br>
         <p>In order to get a better sense of the unique characteristics of our potential user base, and to help to find a target audience segment, we begin with observation and an exercise in empathy. To do so, we make detailed empathy maps of four subjects from a variety of backgrounds, based on videos freely available on Youtube. Empathy maps focus observation by forcing the observer to consider not only what the subject says and does, but what they think and feel. 
            <br>
            <br>
            Below are introductions and empathy maps of four sight-diminished subjects discussing and demonstrating how they interact with technology. For each subject we present a brief background setting, followed by an empathy map with a list of observations.
            </p>
         <br>
            <img class="image_map" src="empathy map 1.PNG" alt="empathy map1">
            <br>
            <br>
            
            <h3>User 1: Partially Blind Redditor</h3>
            <br/>
            <p>
            “GrumpyThing”  is a longtime Redditor, and active internet user with her own Youtube channel which she updates regularly. She and her father have congenital cataracts that have reduced their vision to between 2% - 5% of the average sighted person. She prefers to use her limited vision to access the internet: she reads the screen closely, keeping her head about 1” from the screen and moving it a great physical distance to scan across the page. She types her response by feel, but prefers to look over what she’s typed to verify that it’s not “gibberish.” She’s not ashamed to refer to her condition as an impediment, and talks regularly about wanting to be able to interact with the internet like a “regular person.” More recently, she uses her Samsung Galaxy S10 cell phone “most of the time” to access the internet. She zooms in very close on the text. She is not afraid to take advice from others or to update the way that she interacts with technology -- for example, someone suggested that she move to black background and white text, which she finds quite helpful. She uses limited-to-no aural feedback to help her browse.
            </p>
            <br>
            <hr>
            <br>
            <img class="image_map" src="empathy map 2.PNG" alt="empathy map2">
            <br>
            <br>

                <h3>User 2: Totally Blind Internet Browsing User</h3>
            </br>
            <p>
                “Mike” is totally blind, a natural Russian speaker who now lives in Hanover, though he communicates in this video in English. He navigates the internet with an assistive software called NVDA, a screen reader. Throughout the video he is often lost in webpages, getting errors and warning messages about being on the “last element,” or “unnamed element.”  Often he bemoans poor alt-text and overly graphical webpages, which have poor “accessibility” features. Like GrumpyThing, he is not afraid to refer to his condition as a kind of handicap, or suggest that he needs accessibility software. He accepts help from a friend, Jason, who helps him to film the video. Mike is very detail oriented, and seems to enjoy describing how to use his system in great detail. He seems to have little trouble with all the minutiae of the command interface, which appears to be rather complex (using an entire keyboard). This attention to detail is reflected in his obsession with Music Charts (dates and figures), which he discusses in the video as an example use-case for browsing.  He does not use a mouse, instead relying entirely on the aural feedback from the system.  Throughout the video, he moves his head to help orient himself to the sounds of his speakers. Mike appears to live with his parents, though he looks a little older than most who still live at home. 
            </p>
            <br>
            <hr>
            <br>
            <img class="image_map" src="empathy map 3.PNG" alt="empathy map3">
            <br>
            <br>
                <h3>User 3: Blind From Birth Technologist</h3>
            
            </br>
            <p>“Molly” became blind because of Retinitis Pigmentosa at just 4 years old and began public speaking at age 5. She is an American girl who lives in Los Angeles. She started training when her doctor told her that she had a huge possibility to become blind. So compared to those who have been non-sighted from birth, she knew more about how to use different technologies, and she memorized the keyboard well. Throughout the video, she moves her fingers around her iPhone to let the VoiceOver help her navigate different apps and read mails for her. Although VoiceOver supports her well, she still touches some buttons accidentally and can not go directly to the place she wants.
            </p>

            <br>
            <hr>
            <br>
            <img class="image_map" src="empathy map 4.PNG" alt="empathy map4">
            <br>
            <br>
                <h3>User 4: Blind Film Director and Instagram User
                </h3>:</br>
                <p>“James” is a born blind film director. He moved to Los Angeles and researched in the area of independence and accessibility for blind people. He interviewed the CEO of Apple and he directed a multi-year commercial film for Tommy Hilfiger. He had a lot of words to say about image descriptors. Throughout the video, he seems not satisfied with the screen reader in the market and he believes the reader can be better. He also points out the image descriptor of Instagram is useless which could not help blind people to understand what the image is about. He is looking forward to a better image descriptor that shows every detail of the image or provides a story for the image in a few sentences.
            </p>
        </div>
	<br>
            <hr>
            <br>

        <div class="container">
            <h3>II. Identifying the Problem</h3>
               <p>
                Being blind comes with a lot of constraints on its own. Additionally, technological devices used in our daily lives are often not designed to accommodate the visually impaired. This includes personal computers and smartphone devices. With the help of special accessibility software, blind people can still interact with a computer and navigate the internet. However, these too are not perfect, and they restrict the amount of information the users can gain from websites, making the experience of browsing the internet often frustrating.
                <br>
                <br>
                An article published in the International Journal of Human-Computer Interaction in 2007 [1] identified several causes of frustration among blind people when interacting with computers. These include confusing page layouts, bad screen-reader feedback, conflicts between screen-readers and applications, wrong image annotations, poorly designed forms, misleading links, etc. World Wide Web Consortium (W3C) has guidelines to guide web developers and instruct them about accessibility, but still, very few designers follow these guidelines [2]. Screen-readers and website designs have evolved since the 2007 article, but many frustrations continue nowadays, as seen in the Observations section.
                <br>
                <br>
                One of the problems identified by observing and listening to visually impaired users is how web page components are placed on the screen. A regular sighted person can quickly identify objects on a computer screen and map website functions to screen positions. For example, the closing button on a browser is typically red and located on one of the top corners of the webpage. In contrast, a visually impaired person cannot easily map these functionalities to colors or locations. One of the viable solutions to this problem should allow blind users to identify objects spatially on a web page via audio feedback.
                <br>
                <br></p>
                <div class="citation">[1] Lazar, Jonathan, Aaron Allen, Jason Kleinman, and Chris Malarkey. 2007. "What frustrates screen reader users on the web: A study of 100 blind users." <cite>International Journal of human-computer interaction</cite> 22, no. 3: 247--269.</br>

[2] Kaur, Navdeep, and Vijay Kumar. 2012. "Framework for covering the limitations of web accessibility improvement tools." <cite>International Journal of Computer Science Research</cite>, 3 (1): 27--31.</div>
                


                   
           </div> 
    	<br>
            <hr>
            <br>
       
           <div class="container">
            <h3>III. Developing Personas and the Mental Models Chart</h3>
            <p>Bridge sentences</p>
            <br>
            <h4>Step 1: List Distinguishing Behaviours</h4>
            <p>The first step is to list all user behaviors of the non-sighted society subgroup. See the following table.</p>
            <table><tr>
            <td><img src="raw list.PNG" alt="raw list" ALIGN="mid" width=100% height=auto></td>
            <td><img src="raw list 1.PNG" alt="raw list1" ALIGN="mid" width=100% height=auto></td>
            </tr></table>
            
            <br>
            <h4>Step 2: Group By Behavior</h4>
            <p>For behaviors that fall into similar task-based categories, we group them together and identify which segments of the non-sighted group would exhibit these behaviors. See the following tables.</p>
            <img class="image_map" src="group for behaviors1.PNG" alt="group for behaviors1">
            <img class="image_map" src="group for behaviors2.PNG" alt="group for behaviors2">
            <img class="image_map" src="group for behaviors3.PNG" alt="group for behaviors3">
            <img class="image_map" src="group for behaviors4.PNG" alt="group for behaviors4">
            <br>
            <br>
            <img class="image_map" src="grouped1.PNG" alt="grouped1">
            <img class="image_map" src="grouped2.PNG" alt="grouped2">
            <img class="image_map" src="grouped3.PNG" alt="grouped3">
            <br>
            <h4>Step 3: Name the Groups</h4>
            <p>After step 2 and this step, we can eliminate some behaviors maybe max should write this part.</p>
            <br>
            <img class="image_map" src="audience segments1.PNG" alt="audience segments1">
            <img class="image_map" src="audience segments2.PNG" alt="audience segments2">
               <p>
                   <br>
                   <p>Bridge sentences</p>
                <b>The tech savvy cultural enthusiast.</b> This person is quite comfortable with their limited vision. They enjoy using it as an opportunity to constantly seek out new technologies that offer new ways to interact with the world. They are open to using synaesthetic substitutions for sight. They browse the internet frequently, either alone or in company, and make extensive use of assistive software, which they enjoy learning. However, they are always looking for the newest assistive feature. They appreciate error notifications from the software, telling them that they’re trying to move past the edge of a page, for example. The tech savvy enthusiast has interests in great detail, minutiae, and likes to use the internet as a source of information. They browse most internet content, but tend towards text-based sites -- not because they are frustrated with not being able to see images and GUIs, but because images do not interest them.
               </p>
               <br>
               <p>
                <b>The “passer.”</b> This person has an internalized notion of “normal” and is often talking about wanting to do things like “normal” (presumedly, sighted) people. They are not ashamed to talk about their vision-loss, but often gripe about the lack of accessibility for many mainstream websites. They tend to orient towards visual-heavy content, though this can be a source of frustration. These users have limited, but some vision, and prefer to use the visual modality for information wherever possible. They magnify screens and read at very close distance; they prefer to use their cell-phones rather than a dedicated station with assistive software/hardware. When using assistive software (which is very rare), they are frustrated with having to learn how to operate it. They are often hoping for better technology to come along, which can help to bring a “normal”(what they see as normal) experience of the internet to them. They are very creative, and are active in internet communities; either by moderating on online forums, or creating content on YouTube.
               </p>
               <br>
               <p>
                <b>The text-oriented navigator.</b> This person enjoys accessing a limited, text-based part of the internet. Perhaps blind from birth, they were introduced at an early age to one particular screen-reading software. They know how to use this software very well, and are reluctant to move to a new technology, even if the state of the art has improved in the years since they were introduced to their assistive software of choice. When their navigation points them towards visuals-heavy websites, they feel frustrated. This kind of user is highly dependent on literal verbal feedback; they prefer to have concrete instructions from a screen reader rather than an abstract representation (they would not prefer an aural icon, for example).
               </p> 
               <br>
               <p>
                <b>The in-transition.</b> This person is losing their sight and adjusting to life with limited vision. They are generally young, but can also be middle-aged; but marked by a transition point in their life. At this stage, they are less interested in learning assistive technologies, and more interested in using their existing tools to cope with a limited vision (e.g., by zooming in close on screens, both physically and digitally). They are greatly interested in visual things, which can be a source of frustration. When software reports back error notifications (e.g., you are trying to scroll past the edge of a page, you have entered a URL that cannot be reached (due to a typo)) they are quite frustrated. They browse the full extant of the normative internet, but are not yet convinced that assistive technology is necessary.
               </p> 
               <br>
               <p>
                <b>The elderly dependent.</b> This person has lived a sighted life, and in their final years is not interested in learning new technology. They rely on the help of others to navigate the internet; often having others read screens to them. They will likewise dictate content to a helper who will then type for them. They are quite sharp and would like more intellectual stimulation, but are reluctant to interact with the internet in any way that requires new learning. Any assistive technology they use would have to be completely transparent and require little training, for example being based in natural language.
               </p>
               <h4>Step 4: Personas</h4>
               <img src="James Rath.jpg" alt="James's appearance" ALIGN="left" width=15% height=auto HSPACE="25" VSPACE="25"/>  
               <p>Age:25</br>
                Gender: Male</br>
                James is a tech-savvy cultural lover, legally blind film director, accessibility advocate, and speaker. He has never been defeated by his poor eyesight. Instead, he uses all different technologies to support his daily life. With the help of skills, he likes hiking, horse riding, games, and steering boats. He became an accessibility consultant in the fields of games, movies, and technology. He wants new technology to support him to surf the internet quickly and get all the information he wants. He is not interested in the way the picture looks. Instead, he hopes that all images have detailed descriptions so that he can listen to them to understand.
                </p>
                <br>
                <img src="Carrie.jpg" alt="Carrie's appearance" ALIGN="left" width=15% height=auto HSPACE="25" VSPACE="25"/> 
                <p>
                Age: 27</br>
                Gender: Female</br>
                Carrie is the “passer”. She posts a lot of videos on YouTube about live accessibility. Her mission is to share resources, information, and tools that can help others live accessible, regardless of blindness or low vision. She wants new technologies to help the blind community to live like “normal”. She is willing to talk about herself and tell everyone else that she is legally blind to support and encourage all other blind people. Although she has introduced many technologies in her videos, she is still willing to have a new technology that is easier to use. 
                </p>
                <br>
                <br>
                <img src="Getty.jpg" alt="Getty's appearance" ALIGN="left" width=15% height=auto HSPACE="25" VSPACE="25"/> 
                <p>
                    Age: 70</br>
                    Gender: Female</br>
                    Getty is the text-oriented navigator. She walked with a retractable cane. She read braille and ordered books on tape. She used to have a silver cube that looks like a wireless speaker, and whenever she presses it, the electronic device told her the time. She is only interested in the daily news that could be the only time that she needs the internet. She is afraid of using new technologies. First, she thinks they are hard to learn. Secondly, she is not willing to try something new unless all her friends are using it.
                </p>
           </div>
	<br>
            <hr>
            <br>

           <div class="container">
            <h3>IV. Illustrating a Use Case Scenario</h3>
               <p>
                   QAQ
               </p>    
           </div>
	<br>
            <hr>
            <br>

           <div class="container">
            <h3>V. Finding Related Products</h3>
               <p>
                There are different software available for browsing the internet for blind and visually-impaired people. When using personal computers, there are two popular options, NVDA and JAWS. For mobile devices, one of the users' favorites is Apple's VoiceOver.
                <br>
                <h4>NVDA</h4>
                <img src="NVDA.PNG" alt="NVDA's appearance" ALIGN="left" width=15% height=auto>
                <p>The NVDA software system allows blind and vision-impaired people to access and interact with the internet by providing screen reader technology. It is only available for personal computers with Windows operating systems. However, it is 100% free to download and install and is available in 50+ languages. Its users have described the system as "light," "fast," and "portable." It can be portable on a USB stick and installed on any computer the user has access to. The software is open-source and globally accessible. The fact that it is free has allowed a lot of people to access computers and the internet. Its user base has been steadily growing in the past years, and it is constantly improving. However, users report a series of bugs particular to the browser and specific third-party applications.</p>
                <br>
                <h4>JAWS</h4>
                <img src="JAWS.PNG" alt="JAW's appearance" ALIGN="left" width=20% height=auto>
                <p>JAWS is the world's most popular screen reader software. It provides speech and Braille output for various computer applications on personal computers with Windows operating systems, allowing users to navigate with mouse and keystrokes. It is a paid software maintained by Freedom Scientific. A perpetual home license
                    costs 1000 USD, while the next most affordable option is a personal Annual
                    License costing 95 USD/year, valid for U.S. customers only. Once the best choice in the market, JAWS has been losing its popularity since more affordable assistive technology became available. Users report that the system is stable and reliable, but the price factor is very limiting. However, there is good customer support for users, and there are periodic updates to include new application compatibility.                    
                    </p>
                <br>
                <h4>VoiceOver</h4>
                <img src="VoiceOver.PNG" alt="VoiceOver's appearance" ALIGN="left" width=15% height=auto>
                <p>VoiceOver is an assistive technology developed by Apple and is only available on iOS devices. It consists of a gesture-based screen reader for iPhone and iPad users that cannot see the screen. It provides audible descriptions of what's on the screen, including but not limited to battery level, incoming caller's name, and which app the user's finger is on. Its settings are easily adaptable and adjustable depending on the user's needs, for example, slowing down the reader's voice. In addition, VoiceOver benefits from the touch-screen to give tactile feedback when users are pressing, holding, dragging their fingers on the screen. The system is regularly updated and is made available on each iOS update.
                </p>
           </div>
	<br>
            <hr>
            <br>

           <div class="container">
            <h3>VI. Comparing Products</h3>
               <p>
                After conducting interviews with 100 blind users, Lazar et al. [1] found that 2 of the top 10 causes of frustration when using the internet included (a) page layout causing confusing screen reader feedback; and (b) conflict between screen-reader and application. Although evolving software systems are available for screen-reading and screen assistance, users still face problems interacting with unknown websites. They have trouble with the placement of content on web pages. Commonly used screen-readers, such as NVDA and JAWS, are limited on the amount of information the user gains since they depend on pressing a key or dragging a mouse. For example, when visiting a new website, users may get descriptions of images and text. Still, they may not be able to visualize the placement of the website components. VoiceOver does this job better because the user can touch the screen and feel where objects are placed referent to the screen. However, this technology is not available for personal computers, and it is limited to iOS devices. Our project proposes a solution that will allow PC users to quickly identify the placement of components in a website without having to drag a mouse or tap the keyboard. It will incorporate the user’s movement with audio feedback to indicate where objects are located, therefore facilitating the exploration of websites.
                </br>
                <div class="citation">[1] Lazar, Jonathan, Aaron Allen, Jason Kleinman, and Chris Malarkey. 2007. "What frustrates screen reader users on the web: A study of 100 blind users." <cite>International Journal of human-computer interaction</cite> 22, no. 3: 247-269.</div>

                
               </p>    
           </div>
	<br>
            <hr>
            <br>

           <div class="container">
            <h3>VII. Designing at a High Level</h3>
               <p>
                   QAQ
               </p>    
           </div>
	<br>
            <hr>
            <br>

           <div class="container">
            <h3>VIII. Justifying Feasibility</h3>
               <p>
                   QAQ
               </p>    
           </div>
</body>
</html>
