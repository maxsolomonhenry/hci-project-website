<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>ECSE424 Group 13 Notebook Observation and Proposal</title>
    <link rel='stylesheet' href='bootstrap.min.css'>
    <link rel='stylesheet'
        href='https://cdnjs.cloudflare.com/ajax/libs/material-design-iconic-font/2.2.0/css/material-design-iconic-font.min.css'>
    <link rel="stylesheet" href="style1.css">
    <script src="notebookEngine.js"></script>
    <!-- <script src="scrapeTest.js" defer></script> -->
    <style>
        h1 {
            text-align: center;
        }

        h2 {
            text-align: center;
        }

        h3,
        .h3 {
            text-align: center;
            font-size: 150%;
        }

        h4,
        .h4 {
            text-align: center;
            font-size: 120%;
        }

        .center {
            display: block;
            margin-left: auto;
            margin-right: auto;
            width: 50%;
        }

        .container {
            text-align: left;
            font-size: 18px;
        }

        .image_map {
            width: 100%;
            height: auto;
        }

        .citation {
            font-size: 10px;
        }

        .cite {
            font-style: italic;
        }

        /* The navigation bar */
        .container-fluid {
            overflow: auto;
            background-color: #263238;
            position: fixed;
            /* Set the navbar to fixed position */
            top: 0;
            /* Position the navbar at the top of the page */
            width: 100%;
            /* Full width */
        }

        /* Links inside the navbar */
        .container-fluid a {
            float: left;
            display: block;
            color: #f2f2f2;
            text-align: center;
            padding: 12px;
            text-decoration: none;
            width: 400px;
        }

        /* Change background on mouse-over */
        .container-fluid a:hover {
            background: #ddd;
            color: black;
        }
    </style>
</head>

<body>

    <div id="viewport">
        <!-- Sidebar -->
        <div id="sidebar">
            <header>
                <a href="#">Deliverables</a>
            </header>
            <ul class="nav">
                <li>
                    <a href="index.html">
                        Home
                    </a>
                </li>
                <li>
                    <a href="Observation.html" class="active">
                        Observations and Proposal
                    </a>
                </li>
                <li>
                    <a href="l-fi-prototype.html">
                        Low-Fidelity Prototype and Test Plan
                    </a>
                </li>
                <li>
                    <a href="Computer-Prototype.html">
                        Computer Prototype
                    </a>
                </li>
                <li>
                    <a href="Formative Feedback.html">
                        Formative Feedback
                    </a>
                </li>
                <li>
                    <a href="Alpha_System.html">
                        Alpha System
                    </a>
                </li>
                <li>
                    <a href="Beta_System.html">
                        Beta System
                    </a>
                </li>
            </ul>
        </div>
        <!-- Content -->
        <div id="content">
            <nav class="navbar navbar-default">
                <div class="container-fluid">
                    <a href="index.html">Prev: HomePage</a>
                    <a href="index.html">Home</a>
                    <a href="l-fi-prototype.html">Next: Low-Fidelity Prototype</a>
                </div>
            </nav>
            <h1>Welcome to ECSE424 HCI Group 13 Notebook</h1>
            <h2>Observations and Proposal</h2>
            <br>
            <hr>
            <br>
            <div class="container">
                <h3>I. Observing Users</h3>
                <br>
                <p>In order to get a better sense of the unique characteristics of our potential user base, and to help
                    to find a target audience segment, we begin with observation and an exercise in empathy. To do so,
                    we make detailed empathy maps of four subjects from a variety of backgrounds, based on videos freely
                    available on Youtube. Empathy maps focus observation by forcing the observer to consider not only
                    what the subject says and does, but what they think and feel.
                    <br>
                    <br>
                    Below are introductions and empathy maps of four sight-diminished subjects discussing and
                    demonstrating how they interact with technology. For each subject we present a brief background
                    setting, followed by an empathy map with a list of observations. A Youtube video for each is subject
                    linked at the first word of each paragraph.
                </p>
                <br>
                <br>

                <h4>User 1: Partially Blind Redditor</h4>

                <p>
                    <a href="https://www.youtube.com/watch?v=mgWwUPrDRHE">“GrumpyThing”</a> is a longtime Redditor, and
                    active internet user with her own Youtube channel which she updates regularly. She and her father
                    have congenital cataracts that have reduced their vision to between 2% - 5% of the average sighted
                    person. She prefers to use her limited vision to access the internet: she reads the screen closely,
                    keeping her head about 1” from the screen and moving it a great physical distance to scan across the
                    page. She types her response by feel, but prefers to look over what she’s typed to verify that it’s
                    not “gibberish.” She’s not ashamed to refer to her condition as an impediment, and talks regularly
                    about wanting to be able to interact with the internet like a “regular person.” More recently, she
                    uses her Samsung Galaxy S10 cell phone “most of the time” to access the internet. She zooms in very
                    close on the text. She is not afraid to take advice from others or to update the way that she
                    interacts with technology -- for example, someone suggested that she move to black background and
                    white text, which she finds quite helpful. She uses limited-to-no aural feedback to help her browse.
                </p>
                <img class="image_map" src="Empathy map 1.PNG" alt="empathy map1">
                <br>
                <br>
                <br>
                <h4>User 2: Totally Blind Internet Browsing User</h4>

                <p>
                    <a href="https://www.youtube.com/watch?v=hcoZAiAbICY">“Mike”</a> is totally blind, a natural Russian
                    speaker who now lives in Hanover, though he communicates in this video in English. He navigates the
                    internet with an assistive software called NVDA, a screen reader. Throughout the video he is often
                    lost in webpages, getting errors and warning messages about being on the “last element,” or “unnamed
                    element.” Often he bemoans poor alt-text and overly graphical webpages, which have poor
                    “accessibility” features. Like GrumpyThing, he is not afraid to refer to his condition as a kind of
                    handicap, or suggest that he needs accessibility software. He accepts help from a friend, Jason, who
                    helps him to film the video. Mike is very detail oriented, and seems to enjoy describing how to use
                    his system in great detail. He seems to have little trouble with all the minutiae of the command
                    interface, which appears to be rather complex (using an entire keyboard). This attention to detail
                    is reflected in his obsession with Music Charts (dates and figures), which he discusses in the video
                    as an example use-case for browsing. He does not use a mouse, instead relying entirely on the aural
                    feedback from the system. Throughout the video, he moves his head to help orient himself to the
                    sounds of his speakers. Mike appears to live with his parents, though he looks a little older than
                    most who still live at home.
                </p>
                <img class="image_map" src="Empathy map 2.PNG" alt="empathy map2">
                <br>
                <br>
                <br>
                <h4>User 3: Blind From Birth Technologist</h4>

                <p><a href="https://www.youtube.com/watch?v=TiP7aantnvE">“Molly”</a> became blind because of Retinitis
                    Pigmentosa at just 4 years old and began public speaking at age 5. She is an American girl who lives
                    in Los Angeles. She started training when her doctor told her that she had a huge possibility to
                    become blind. So compared to those who have been non-sighted from birth, she knew more about how to
                    use different technologies, and she memorized the keyboard well. Throughout the video, she moves her
                    fingers around her iPhone to let the VoiceOver help her navigate different apps and read mails for
                    her. Although VoiceOver supports her well, she still touches some buttons accidentally and can not
                    go directly to the place she wants.
                </p>
                <img class="image_map" src="Empathy map 3.PNG" alt="empathy map3">
                <br>
                <br>
                <br>
                <h4>User 4: Blind Film Director and Instagram User
                </h4>
                <p><a href="https://www.youtube.com/watch?v=767YJe7R-2Y">“James”</a> is a born blind film director. He
                    moved to Los Angeles and researched in the area of independence and accessibility for blind people.
                    He interviewed the CEO of Apple and he directed a multi-year commercial film for Tommy Hilfiger. He
                    had a lot of words to say about image descriptors. Throughout the video, he seems not satisfied with
                    the screen reader in the market and he believes the reader can be better. He also points out the
                    image descriptor of Instagram is useless which could not help blind people to understand what the
                    image is about. He is looking forward to a better image descriptor that shows every detail of the
                    image or provides a story for the image in a few sentences.
                </p>
                <img class="image_map" src="Empathy map 4.PNG" alt="empathy map4">
            </div>
            <br>
            <hr>
            <br>

            <div class="container">
                <h3>II. Identifying the Problem</h3>
                <br>
                <p>
                    Being blind comes with a lot of constraints on its own. Additionally, technological devices used in
                    our daily lives are often not designed to accommodate the visually impaired. This includes personal
                    computers and smartphone devices. With the help of special accessibility software, blind people can
                    still interact with a computer and navigate the internet. However, these too are not perfect, and
                    they restrict the amount of information the users can gain from websites, making the experience of
                    browsing the internet often frustrating.
                    <br>
                    <br>
                    An article published in the International Journal of Human-Computer Interaction in 2007 [1]
                    identified several causes of frustration among blind people when interacting with computers. These
                    include confusing page layouts, bad screen-reader feedback, conflicts between screen-readers and
                    applications, wrong image annotations, poorly designed forms, misleading links, etc. World Wide Web
                    Consortium (W3C) has guidelines to guide web developers and instruct them about accessibility, but
                    still, very few designers follow these guidelines [2]. Screen-readers and website designs have
                    evolved since the 2007 article, but many frustrations continue nowadays, as seen in the Observations
                    section.
                    <br>
                    <br>
                    One of the problems identified by observing and listening to visually impaired users is how web page
                    components are placed on the screen. A regular sighted person can quickly identify objects on a
                    computer screen and map website functions to screen positions. For example, the closing button on a
                    browser is typically red and located on one of the top corners of the webpage. In contrast, a
                    visually impaired person cannot easily map these functionalities to colors or locations. One of the
                    viable solutions to this problem should allow blind users to identify objects spatially on a web
                    page via audio feedback.
                    <br>
                    <br>
                </p>
                <div class="citation">[1] Lazar, Jonathan, Aaron Allen, Jason Kleinman, and Chris Malarkey. 2007. "What
                    frustrates screen reader users on the web: A study of 100 blind users." <cite>International Journal
                        of human-computer interaction</cite> 22, no. 3: 247--269.</br>

                    [2] Kaur, Navdeep, and Vijay Kumar. 2012. "Framework for covering the limitations of web
                    accessibility improvement tools." <cite>International Journal of Computer Science Research</cite>, 3
                    (1): 27--31.</div>




            </div>
            <br>
            <hr>
            <br>

            <div class="container">
                <h3>III. Developing Personas and the Mental Models Chart</h3>
                <br>
                <p>In this section we follow the methodology to develop task-based audience segments, in order to gain
                    insight into how our target population may self-sort into valuable behavioural patterns. We begin
                    with a large "brain dump" of as many tasks as we can think of that are associated with navigating
                    the internet while blind or visually impaired. We generate a list of over 100 tasks. These tasks are
                    then attributed to a handful of likely "actors." The cast of eight actors emerges from sorting
                    through the tasks. In the final step, actors and tasks are loosely arranged into clusters called
                    groups, each representing an audience segment that may want to use our product. The groups are
                    "brought to life" in personas, which are listed below.</p>
                <br>
                <h4>Step 1: List Distinguishing Behaviours</h4>
                <p>The first step is to list all user behaviors of the blind and visually vision-impaired society
                    subgroup. See the following table for the full list of tasks.</p><br>
                <table>
                    <tr>
                        <td><img src="raw list.PNG" alt="raw list" ALIGN="mid" width=100% height=auto></td>
                        <td><img src="raw list 1.PNG" alt="raw list1" ALIGN="mid" width=100% height=auto></td>
                    </tr>
                </table>

                <br>
                <h4>Step 2: Group By Behavior</h4>
                <p>For behaviors that fall into similar task-based categories, we group them together and identify which
                    segments of the non-sighted group would exhibit these behaviors. We identify eight principle actors:
                    blind form birth, recently blind, very poor sighted, old grandparents, dependants, those gradually
                    losing their sight, technology keeners, and blind-embarrased.</p> <br>
                <img class="image_map" src="group for behaviors1.PNG" alt="group for behaviors1">
                <img class="image_map" src="group for behaviors2.PNG" alt="group for behaviors2">
                <img class="image_map" src="group for behaviors3.PNG" alt="group for behaviors3">
                <img class="image_map" src="group for behaviors4.PNG" alt="group for behaviors4">
                <br>
                <br>
                <br>
                <p>By coloring the x-marks and rearranging the rows (the tasks) we form rough groups. See below:</p>
                <br>
                <br>
                <img class="image_map" src="grouped1.PNG" alt="grouped1">
                <img class="image_map" src="grouped2.PNG" alt="grouped2">
                <img class="image_map" src="grouped3.PNG" alt="grouped3">
                <br>
                <nr></nr>
                <br>
                <h4>Step 3: Name the Groups</h4>
                <p>Finally, we collect all tasks associated with each groups, and assign them names that seem the most
                    appropriate as shorthands for each collection of behaviours. We come up with the following names:
                    the tech savvy cultural enthusiast, the passer, the text-oriented navigator, the in-transition, and
                    the elderly dependant.</p>
                <br>
                <img class="image_map" src="audience segments1.PNG" alt="audience segments1">
                <img class="image_map" src="audience segments2.PNG" alt="audience segments2">
                <p>
                    <br>
                <h4>Descriptions of Audience Segments</h4>
                <b>The tech savvy cultural enthusiast.</b> This person is quite comfortable with their limited vision.
                They enjoy using it as an opportunity to constantly seek out new technologies that offer new ways to
                interact with the world. They are open to using synaesthetic substitutions for sight. They browse the
                internet frequently, either alone or in company, and make extensive use of assistive software, which
                they enjoy learning. However, they are always looking for the newest assistive feature. They appreciate
                error notifications from the software, telling them that they’re trying to move past the edge of a page,
                for example. The tech savvy enthusiast has interests in great detail, minutiae, and likes to use the
                internet as a source of information. They browse most internet content, but tend towards text-based
                sites -- not because they are frustrated with not being able to see images and GUIs, but because images
                do not interest them.
                </p>
                <br>
                <p>
                    <b>The “passer.”</b> This person has an internalized notion of “normal” and is often talking about
                    wanting to do things like “normal” (presumedly, sighted) people. They are not ashamed to talk about
                    their vision-loss, but often gripe about the lack of accessibility for many mainstream websites.
                    They tend to orient towards visual-heavy content, though this can be a source of frustration. These
                    users have limited, but some vision, and prefer to use the visual modality for information wherever
                    possible. They magnify screens and read at very close distance; they prefer to use their cell-phones
                    rather than a dedicated station with assistive software/hardware. When using assistive software
                    (which is very rare), they are frustrated with having to learn how to operate it. They are often
                    hoping for better technology to come along, which can help to bring a “normal”(what they see as
                    normal) experience of the internet to them. They are very creative, and are active in internet
                    communities; either by moderating on online forums, or creating content on YouTube.
                </p>
                <br>
                <p>
                    <b>The text-oriented navigator.</b> This person enjoys accessing a limited, text-based part of the
                    internet. Perhaps blind from birth, they were introduced at an early age to one particular
                    screen-reading software. They know how to use this software very well, and are reluctant to move to
                    a new technology, even if the state of the art has improved in the years since they were introduced
                    to their assistive software of choice. When their navigation points them towards visuals-heavy
                    websites, they feel frustrated. This kind of user is highly dependent on literal verbal feedback;
                    they prefer to have concrete instructions from a screen reader rather than an abstract
                    representation (they would not prefer an aural icon, for example).
                </p>
                <br>
                <p>
                    <b>The in-transition.</b> This person is losing their sight and adjusting to life with limited
                    vision. They are generally young, but can also be middle-aged; but marked by a transition point in
                    their life. At this stage, they are less interested in learning assistive technologies, and more
                    interested in using their existing tools to cope with a limited vision (e.g., by zooming in close on
                    screens, both physically and digitally). They are greatly interested in visual things, which can be
                    a source of frustration. When software reports back error notifications (e.g., you are trying to
                    scroll past the edge of a page, you have entered a URL that cannot be reached (due to a typo)) they
                    are quite frustrated. They browse the full extant of the normative internet, but are not yet
                    convinced that assistive technology is necessary.
                </p>
                <br>
                <p>
                    <b>The elderly dependent.</b> This person has lived a sighted life, and in their final years is not
                    interested in learning new technology. They rely on the help of others to navigate the internet;
                    often having others read screens to them. They will likewise dictate content to a helper who will
                    then type for them. They are quite sharp and would like more intellectual stimulation, but are
                    reluctant to interact with the internet in any way that requires new learning. Any assistive
                    technology they use would have to be completely transparent and require little training, for example
                    being based in natural language.
                </p>
                <h4>Step 4: Personas</h4>
                <p>Below are three personas based on the audience segments we discovered through the task-based
                    segmenting exercise. The characters are fictional, but give us a sense of who we might target our
                    product at, how they might react when using it, and what they might use it for.</p>
                <br>
                <br>
                <img src="James Rath.jpg" alt="James's appearance" ALIGN="left" width=15% height=auto HSPACE="25"
                    VSPACE="25" />
                <p><b>Age:</b> 25</br>
                    <b>Gender:</b> Male</br>
                    <i>James</i> is a tech-savvy cultural lover, legally blind film director, accessibility advocate,
                    and speaker. He has never been defeated by his poor eyesight. Instead, he uses all different
                    technologies to support his daily life. With the help of skills, he likes hiking, horse riding,
                    games, and steering boats. He became an accessibility consultant in the fields of games, movies, and
                    technology. He wants new technology to support him to surf the internet quickly and get all the
                    information he wants. He is not interested in the way the picture looks. Instead, he hopes that all
                    images have detailed descriptions so that he can listen to them to understand.
                </p>
                <br>
                <img src="Carrie.jpg" alt="Carrie's appearance" ALIGN="left" width=15% height=auto HSPACE="25"
                    VSPACE="25" />
                <p>
                    <b>Age:</b> 27</br>
                    <b>Gender:</b> Female</br>
                    <i>Carrie</i> is the “passer”. She posts a lot of videos on YouTube about live accessibility. Her
                    mission is to share resources, information, and tools that can help others live accessible,
                    regardless of blindness or low vision. She wants new technologies to help the blind community to
                    live like “normal”. She is willing to talk about herself and tell everyone else that she is legally
                    blind to support and encourage all other blind people. Although she has introduced many technologies
                    in her videos, she is still willing to have a new technology that is easier to use.
                </p>
                <br>
                <br>
                <img src="Getty.jpg" alt="Getty's appearance" ALIGN="left" width=15% height=auto HSPACE="25"
                    VSPACE="25" />
                <p>
                    <b>Age:</b> 70</br>
                    <b>Gender:</b> Female</br>
                    <i>Getty</i> is the text-oriented navigator. She walked with a retractable cane. She read braille
                    and ordered books on tape. She used to have a silver cube that looks like a wireless speaker, and
                    whenever she presses it, the electronic device told her the time. She is only interested in the
                    daily news that could be the only time that she needs the internet. She is afraid of using new
                    technologies. First, she thinks they are hard to learn. Secondly, she is not willing to try
                    something new unless all her friends are using it.
                </p>
            </div>
            <br>
            <hr>
            <br>

            <div class="container">
                <h3>IV. Illustrating a Use Case Scenario</h3>
                <br>
                <p>
                    James is seeking new technologies today and he suddenly finds our product on the website. He is
                    someone who wants technologies to help him gathering information quickly. Our product does fit his
                    needs. He can stay in his office, wear his headphones and microphones, and tell our product what he
                    wants to navigate. Our product will speak to him about all the choices on the website. Our product’s
                    3D website will contain outstanding image descriptors and text readers. James will love our product
                    very much. James is a famous YouTuber, so he posts a video about our technology. After several days
                    Carrie knows the video and is curious about our product. She aims to share technologies to support
                    blind people’s life better and wishes to action like “normal”. She is legally non-sighted, and she
                    knows some basics about the internet. But technologies in the market are still slower down her life.
                    Our product is what she wants, she can navigate the website like “normal” people and our product
                    will be easy to use. Carrie is willing to share our products with the blind community. However, they
                    do not have any connections to Getty. That’s where we need to think about another way of
                    advertising. We can go to help centers and communities to talk with text-oriented navigators and
                    give them free trying opportunities. Getty will try our product when her friends are mostly covered.
                    So our main targets at the first steps are tech-savvy cultural lovers and “passer”. These people are
                    more willing to try new technologies and love to share with other blind people.
                </p>
            </div>
            <br>
            <hr>
            <br>

            <div class="container">
                <h3>V. Finding Related Products</h3>
                <br>
                <p>
                    There are different software available for browsing the internet for blind and visually-impaired
                    people. When using personal computers, there are two popular options, NVDA and JAWS. For mobile
                    devices, one of the users' favorites is Apple's VoiceOver.
                    <br>
                    <br>
                <h4>NVDA</h4>
                <img src="NVDA.PNG" alt="NVDA's appearance" ALIGN="left" width=15% height=auto>
                <p>The NVDA software system allows blind and vision-impaired people to access and interact with the
                    internet by providing screen reader technology. It is only available for personal computers with
                    Windows operating systems. However, it is 100% free to download and install and is available in 50+
                    languages. Its users have described the system as "light," "fast," and "portable." It can be
                    portable on a USB stick and installed on any computer the user has access to. The software is
                    open-source and globally accessible. The fact that it is free has allowed a lot of people to access
                    computers and the internet. Its user base has been steadily growing in the past years, and it is
                    constantly improving. However, users report a series of bugs particular to the browser and specific
                    third-party applications.</p>
                <br>
                <h4>JAWS</h4>
                <img src="JAWS.PNG" alt="JAW's appearance" ALIGN="left" width=20% height=auto>
                <p>JAWS is the world's most popular screen reader software. It provides speech and Braille output for
                    various computer applications on personal computers with Windows operating systems, allowing users
                    to navigate with mouse and keystrokes. It is a paid software maintained by Freedom Scientific. A
                    perpetual home license
                    costs 1000 USD, while the next most affordable option is a personal Annual
                    License costing 95 USD/year, valid for U.S. customers only. Once the best choice in the market, JAWS
                    has been losing its popularity since more affordable assistive technology became available. Users
                    report that the system is stable and reliable, but the price factor is very limiting. However, there
                    is good customer support for users, and there are periodic updates to include new application
                    compatibility.
                </p>
                <br>
                <h4>VoiceOver</h4>
                <img src="VoiceOver.PNG" alt="VoiceOver's appearance" ALIGN="left" width=15% height=auto>
                <p>VoiceOver is an assistive technology developed by Apple and is only available on iOS devices. It
                    consists of a gesture-based screen reader for iPhone and iPad users that cannot see the screen. It
                    provides audible descriptions of what's on the screen, including but not limited to battery level,
                    incoming caller's name, and which app the user's finger is on. Its settings are easily adaptable and
                    adjustable depending on the user's needs, for example, slowing down the reader's voice. In addition,
                    VoiceOver benefits from the touch-screen to give tactile feedback when users are pressing, holding,
                    dragging their fingers on the screen. The system is regularly updated and is made available on each
                    iOS update.
                </p>
            </div>
            <br>
            <hr>
            <br>

            <div class="container">
                <h3>VI. Comparing Products</h3>
                <br>
                <p>
                    After conducting interviews with 100 blind users, Lazar et al. [1] found that 2 of the top 10 causes
                    of frustration when using the internet included (a) page layout causing confusing screen reader
                    feedback; and (b) conflict between screen-reader and application. Although evolving software systems
                    are available for screen-reading and assistance, users still face problems interacting with unknown
                    websites. They have trouble with the placement of content on web pages. Commonly used
                    screen-readers, such as NVDA and JAWS, are limited on the amount of information the user gains since
                    they depend on pressing a key or dragging a mouse. For example, when visiting a new website, users
                    may get descriptions of images and text. Still, they may not be able to visualize the placement of
                    the website components.
                    <br>
                    <br>
                    VoiceOver does this job better since it allows the user to touch the screen and feel where objects
                    are placed referent to the screen. However, when testing the accessibility and usability problems
                    encountered on websites and mobile apps, Carvalho et al. found that, although mobile apps
                    significantly improve the ability of blind people to perform specific tasks online, they still
                    struggle considerably compared to normal-vision users [2]. The researchers asked users to perform
                    tasks using mobile apps with VoiceOver or Talkback (Android’s equivalent). While non-blind users
                    successfully executed 91.67% of the functions, blind participants only succeeded in 1/3 of the
                    tasks. One of the main problems encountered by the blind participants was that navigation elements
                    were not helpful to find what they were seeking.
                    <br>
                    <br>
                    Therefore, VoiceOver and other mobile assistive technologies still lack functionalities to improve
                    the visually impaired user experience. Our project proposes a solution that will allow PC users to
                    quickly identify the placement of components in a website without having to drag a mouse or tap the
                    keyboard. Instead, it will incorporate the user’s movement with audio feedback to indicate where
                    objects are located, therefore facilitating the exploration of websites.
                    </br>
                <div class="citation">[1] Lazar, Jonathan, Aaron Allen, Jason Kleinman, and Chris Malarkey. 2007. "What
                    frustrates screen reader users on the web: A study of 100 blind users." <cite>International Journal
                        of human-computer interaction</cite> 22, no. 3: 247-269.</div>
                <div class="citation">[2] Carvalho, Michael Crystian Nepomuceno, Felipe Silva Dias, Aline Grazielle
                    Silva Reis, and André Pimenta Freire. 2018. "Accessibility and usability problems encountered on
                    websites and applications in mobile devices by blind and normal-vision users." <cite>In Proceedings
                        of the 33rd Annual ACM Symposium on Applied Computing.</cite> Association for Computing
                    Machinery, New York, NY, USA, 2022–2029.</div>


                </p>
            </div>
            <br>
            <hr>
            <br>

            <div class="container">
                <h3>VII. Designing at a High Level</h3>
                <br>
                <img src="design.jpg" alt="design" width=50% height=auto class="center"><br>
                <p>
                    Our project goal is to develop a system that will help spatialize a website to visually impaired
                    users, by presenting a webpage as its own sonic room: a 3D sonic environment in which each element
                    of the page is "physically" situated. The system will project a 2D webpage to a larger 3D acoustic
                    space (spatialization, sound assignment, and 3D acoustic rendering), allowing users such as James,
                    Carrie, and Getty, to "physically" explore a webpage as they would navigate the world through aural
                    cues.
                    <br><br>
                    As a starting point, the project will focus on a subset of "typical" website layouts that can be
                    unambiguously mapped to a larger, hemi-cylindrical surface that surrounds the user's head. The user
                    wears headphones, and their microphone will be on. The microphone sound will be fed back to the
                    user, but adjusted to adopt the reverberent characteristics of a particular virtual room, giving the
                    user the impression of having traveled to a new space. For example, the new room could sound like a
                    wide and echoic room, like a cave, or a small claustrophobic space, like a vocal booth.
                    <br><br>
                    A webcam or camera device will need to be connected and facing the user's head, and will be
                    responsible for tracking their head movements. The user will navigate to a new webpage, and the
                    system will determine an acoustic reverberant character for the website. The primary elements of the
                    page (e.g., links) are dynamically assigned 3D spatial positions (extending beyond the width of the
                    screen, likely a 180-degree hemi-cylindrical span) and given sonic "signatures" (looping sound
                    effects). The "signatures" are spatialized, i.e., panned left-right and recessed into more- or less-
                    reverb, to paint a 3D auditory scene of the website room.
                    <br><br>
                    The user will be able to navigate inside the room by moving their head. The camera or webcam will
                    capture these movements. As the user moves their head, the internal positions of the sonic objects
                    are remapped to reflect the new head position. Once the user points their face towards an object of
                    interest (e.g., links), they use the keyboard or mouse button to interact with it. (This step may be
                    updated in the future to include voice commands in natural language). <br><br>
                    Finally, and importantly, the system will have a memory for pages visited in the past and will
                    always render pages in the same manner, with the same reverberent characteristics, and the same
                    sonic signatures for each item. This way, the user can develop a sense of familiarity with the pages
                    they visit often.
                </p>
            </div>
            <br>
            <hr>
            <br>

            <div class="container">
                <h3>VIII. Justifying Feasibility</h3>
                <br>
                <p>
                    Testing for this project is quite feesible, as there are relatively few hardware demands for this
                    project, and most devices needed are readily available to most people; these include computers,
                    microphones, webcams and headphones. The system may benefit from a specific microphone rather than a
                    standard laptop mic, and perhaps even a tightly controlled acoustic environment; though
                    head-tracking can be accomplished with a standard laptop webcam and a publically available Google
                    API. A significant challenge will be testing prototypes with target audiences. If visually impaired
                    users cannot participate during the testing phase, simulations will have to be done with users who
                    are not blind but simulate blindness using blindfolds.
                    <br><br>
                    Developing the system involves challenges in a number of disparate domains, including audio signal
                    processing and spatial audio, web design and development, and code optimization to meet the realtime
                    constraints of the system.
                    <br>
                    <br>
                    We see the project as breaking down into a number of easily accomplished subtasks, including:</br>
                <ul>
                    <li>Spatializing a 2D page to some 3D output.</li>
                    <li>Tracking the user's head movement (Google API available for use with their webcam).</li>
                    <li>Rendering 3D audio in realtime (WebAudio has an API for this).</li>
                    <li>Handling the real-time constraints of the browser (it may not be able to handle all processes at
                        once).</li>
                </ul>

                <br>
                The group members have academic and professional experience with audio signal processing, web design and
                development, and general programming practices. Apart from this skill set, there is extensively
                open-source code available, APIs, libraries, and documentation (e.g., Google, WebAudio, as listed
                above).

                The group estimates it will take 4 to 5 weeks to build a system that maps a 2D page to a 3D virtual
                aural space. It will take another 5 to 6 weeks to implement the head-tracking interaction between the
                user and the environment. As mentioned above, due to the modular nature of the subtasks some development
                can be done in parallel; and all group members will collaborate in equal amounts.

                </p>
            </div>
</body>

</html>